<!DOCTYPE html>
<html>
<head>
    <title>Auto Face Recognition</title>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.6.7/dist/face-api.min.js"></script>
    <style>
        :root {
            --bg: #121212; --fg: #e0e0e0; --primary: #00b4d8; --secondary: #2a2a2a;
        }
        body {
            font-family: system-ui, sans-serif; margin: 0; background: var(--bg); 
            color: var(--fg); display: flex; flex-direction: column; align-items: center;
        }
        #video { width: 640px; height: 480px; border-radius: 8px; background: #000; }
        .status {
            background: var(--secondary); padding: 1rem; border-radius: 8px;
            margin: 1rem; max-width: 640px; text-align: center;
        }
        .highlight { color: var(--primary); font-weight: bold; }
    </style>
</head>
<body>
    <video id="video" autoplay muted></video>
    <div class="status" id="status">Initializing...</div>

<script>
(async () => {
    const status = document.getElementById('status');
    const faceMatcher = new faceapi.FaceMatcher();
    let isTraining = false;
    let trainedFaces = 0;
    
    // Load models from CDN
    status.innerHTML = "âš™ï¸ Loading AI models...";
    await faceapi.nets.ssdMobilenetv1.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.6.7/model/');
    await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.6.7/model/');
    await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.6.7/model/');

    // Setup camera
    const video = document.getElementById('video');
    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    video.srcObject = stream;
    
    // Automatic enrollment process
    const enrollUser = async () => {
        if(trainedFaces >= 10) return;
        isTraining = true;
        
        status.innerHTML = `ðŸ‘¤ Please face the camera (User ${trainedFaces+1})<br>
                           <span class="highlight">â–¶ Enrollment in progress...</span>`;
        
        // Capture 5 training samples
        const descriptors = [];
        for(let i = 0; i < 5; i++) {
            const detection = await faceapi.detectSingleFace(video)
                .withFaceLandmarks()
                .withFaceDescriptor();
            if(detection) descriptors.push(detection.descriptor);
            await new Promise(resolve => setTimeout(resolve, 500));
        }

        if(descriptors.length > 0) {
            faceMatcher.add(`User ${++trainedFaces}`, descriptors);
            status.innerHTML = `âœ… User ${trainedFaces} enrolled!<br>
                               <span class="highlight">Auto-continuing in 3 seconds...</span>`;
            setTimeout(enrollUser, 3000);
        } else {
            status.innerHTML = "âŒ Face not detected - please try again";
            setTimeout(enrollUser, 2000);
        }
        isTraining = false;
    };

    // Start recognition loop
    const detectFaces = async () => {
        if(isTraining) return;
        
        const detections = await faceapi.detectAllFaces(video)
            .withFaceLandmarks()
            .withFaceDescriptors();
        
        const labeled = detections.map(d => faceMatcher.findBestMatch(d.descriptor));
        status.innerHTML = labeled.map((l, i) => 
            `ðŸ‘¤ ${l.label} (${Math.round((1 - l.distance) * 100)}% confident)`
        ).join("<br>") || "No faces detected";
    };

    // Start enrollment when ready
    video.addEventListener('play', async () => {
        faceapi.matchDimensions(video, video);
        setTimeout(enrollUser, 1000);
        setInterval(detectFaces, 1000);
    });
})();
</script>
</body>
</html>
